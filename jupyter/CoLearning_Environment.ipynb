{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54071d1d-c68e-4f3d-9fd5-17eba00a9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9bc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = Discrete(5)\n",
    "\n",
    "       \n",
    "      \n",
    "observation_space = Tuple((Discrete(2),Discrete(2)))\n",
    "state = (0,0) #initialise state here\n",
    "\n",
    "\n",
    "\n",
    "# Define transition matrix\n",
    "transition_matrix = {\n",
    "            (0, 0): {0: (0, 0), 1: (1, 0), 2: (2, 0), 3: (0, 0), 4: (0, 1), 5: (0, 2)},\n",
    "            (1, 0): {0: (0, 0), 1: (1, 0), 2: (2, 0), 3: (1, 0), 4: (1, 1), 5: (1, 2)},\n",
    "            (2, 0): {0: (0, 0), 1: (1, 0), 2: (2, 0), 3: (2, 0), 4: (2, 1), 5: (2, 2)},\n",
    "            (0, 1): {0: (0, 1), 1: (1, 1), 2: (2, 1), 3: (0, 0), 4: (0, 1), 5: (0, 2)},\n",
    "            (1, 1): {0: (0, 1), 1: (1, 1), 2: (2, 1), 3: (1, 0), 4: (1, 1), 5: (1, 2)},\n",
    "            (2, 1): {0: (0, 1), 1: (1, 1), 2: (2, 1), 3: (2, 0), 4: (2, 1), 5: (2, 2)},\n",
    "            (0, 2): {0: (0, 2), 1: (1, 2), 2: (2, 2), 3: (0, 0), 4: (0, 1), 5: (0, 2)},\n",
    "            (1, 2): {0: (0, 2), 1: (1, 2), 2: (2, 2), 3: (1, 0), 4: (1, 1), 5: (1, 2)},\n",
    "            (2, 2): {0: (0, 2), 1: (1, 2), 2: (2, 2), 3: (2, 0), 4: (2, 1), 5: (2, 2)}\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "772dc2fd-fc7d-4241-8099-02314e16b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoLearn(Env):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Define an action space containing 6 actions (0-5)\n",
    "\n",
    "        Go to Location A    : 0\n",
    "        Go to Location B    : 1\n",
    "        Go to Location C    : 2\n",
    "        Go to Serve         : 3\n",
    "        Go to Drop          : 4\n",
    "        Go to Place         : 5\n",
    "        '''     \n",
    "        self.action_space = Discrete(5)\n",
    "\n",
    "        '''\n",
    "        Define an observation space containing 9 states (0-8)\n",
    "\n",
    "        State_position          = {Location_A,Location_B,Location_C}\n",
    "        State_handOrientation   = {Serve,Drop,Place}\n",
    "        State_space = State_position x State_handOrientation \n",
    "        State = {(Location_A,Serve),(Location_B,Serve),(Location_C,Serve),(Location_A,Drop)} etc\n",
    "        '''\n",
    "        self.observation_space = Tuple((Discrete(2),Discrete(2)))\n",
    "        self.state = (0,0) #initialise state here\n",
    "\n",
    "        self.episode_length = 10\n",
    "        self.info = {}\n",
    "\n",
    "        # Define transition matrix\n",
    "        self.transition_matrix = {\n",
    "            (0, 0): {0: (0, 0), 1: (1, 0), 2: (2, 0), 3: (0, 0), 4: (0, 1), 5: (0, 2)},\n",
    "            (1, 0): {0: (0, 0), 1: (1, 0), 2: (2, 0), 3: (1, 0), 4: (1, 1), 5: (1, 2)},\n",
    "            (2, 0): {0: (0, 0), 1: (1, 0), 2: (2, 0), 3: (2, 0), 4: (2, 1), 5: (2, 2)},\n",
    "            (0, 1): {0: (0, 1), 1: (1, 1), 2: (2, 1), 3: (0, 0), 4: (0, 1), 5: (0, 2)},\n",
    "            (1, 1): {0: (0, 1), 1: (1, 1), 2: (2, 1), 3: (1, 0), 4: (1, 1), 5: (1, 2)},\n",
    "            (2, 1): {0: (0, 1), 1: (1, 1), 2: (2, 1), 3: (2, 0), 4: (2, 1), 5: (2, 2)},\n",
    "            (0, 2): {0: (0, 2), 1: (1, 2), 2: (2, 2), 3: (0, 0), 4: (0, 1), 5: (0, 2)},\n",
    "            (1, 2): {0: (0, 2), 1: (1, 2), 2: (2, 2), 3: (1, 0), 4: (1, 1), 5: (1, 2)},\n",
    "            (2, 2): {0: (0, 2), 1: (1, 2), 2: (2, 2), 3: (2, 0), 4: (2, 1), 5: (2, 2)}\n",
    "        }\n",
    "        \n",
    "    def step(self,Action=None):\n",
    "        # If no action is given, sample action space\n",
    "        if Action == None:\n",
    "            action = self.action_space.sample()\n",
    "        else:\n",
    "            action = Action\n",
    "\n",
    "        # Lookup the next state based on the action taken\n",
    "        next_state = self.transition_matrix[self.state][action]\n",
    "\n",
    "        # Define reward function (immediate reward)\n",
    "        # Agent will get rewarded more if the state transitions to location C, so it has a 'preference' for this state\n",
    "        if next_state[0] == 0: \n",
    "            reward_preference = 1\n",
    "        elif next_state[0] == 1:\n",
    "            reward_preference = 1\n",
    "        elif next_state[0] == 2:\n",
    "            reward_preference = 10\n",
    "        \n",
    "        # Obtain the reward for task completion\n",
    "        reward_task = self.obtain_reward()\n",
    "        reward = reward_preference + reward_task\n",
    "                \n",
    "        # Decrease remaining episode length  \n",
    "        self.episode_length -= 1\n",
    "\n",
    "        if self.episode_length <=0:\n",
    "            terminated = True\n",
    "        else:\n",
    "            terminated = False\n",
    "\n",
    "        return self.state,reward,terminated,terminated,self.info # TODO: Implement difference between terminated and truncated\n",
    "    \n",
    "    def obtain_reward(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = (0,0)\n",
    "        self.episode_length = 10\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf2ad29c-87c3-4527-a33b-9dc13f9ab635",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CoLearn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "218fd7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1, 1), None, False, False, {})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
